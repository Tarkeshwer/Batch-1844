{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bc8b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a941b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import all neccessory libreries for selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing BeautifulSoup \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# Importing required Exceptions\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fb0c4",
   "metadata": {},
   "source": [
    "Q1. Write a python program which searches all the product under a particular product from www.amazon.in.\n",
    "The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search\n",
    "for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4b1cfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path for web driver\n",
    "driver=webdriver.Chrome(r\"E:\\Flip Robo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99e8e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the webpage\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10c7bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product Name : guitar\n"
     ]
    }
   ],
   "source": [
    "# Asking the user to input the keywords he/she wants to search\n",
    "user_inp = input('Enter the product Name : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1fd32fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1242341340.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [96]\u001b[1;36m\u001b[0m\n\u001b[1;33m    srch_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/header)\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# sending user input to search\n",
    "search_prod = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\").send_keys(product)\n",
    "\n",
    "# Clicking the button to start search\n",
    "srch_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c31739de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'send_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m product\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m product\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m(user_inp)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Clicking the button to start search\u001b[39;00m\n\u001b[0;32m      8\u001b[0m search \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//div[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnav-search-submit nav-sprite\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/span/input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'send_keys'"
     ]
    }
   ],
   "source": [
    "# sending user input to search\n",
    "product=driver.find_elements(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "product.clear()\n",
    "product.send_keys(user_inp)\n",
    "\n",
    "\n",
    "# Clicking the button to start search\n",
    "search = driver.find_elements(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36e880",
   "metadata": {},
   "source": [
    "Q2. In the above question, now scrape the following details of each product listed in first 3 pages of your\n",
    "search results and save it in a data frame and csv. In case if any product has less than 3 pages in search\n",
    "results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page = 0\n",
    "end_page = 3\n",
    "urls = []\n",
    "for page in range(start_page,end_page+1):\n",
    "    try:\n",
    "    page_urls = driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "    # All urls on current page  \n",
    "    for url in page_urls:\n",
    "    url = url.get_attribute('href')\n",
    "    if url[0:4]=='http':\n",
    "    urls.append(url)\n",
    "    print('Product urls of page {} has been scraped.format(page+1)') \n",
    "\n",
    "# for moving to Next Page:\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')\n",
    "    if nxt_button.text == 'Next→':\n",
    "        nxt_button.click()\n",
    "        time.sleep(5)\n",
    "# If the next button is inactive or not working then print breaking loop   \n",
    "    elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':\n",
    "        print(\"No new pages exist. Breaking the loop\")\n",
    "        break\n",
    "\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')\n",
    "        driver.get(next_page)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_dict = {}\n",
    "prod_dict['Brand']=[]\n",
    "prod_dict['Name']=[]\n",
    "prod_dict['Rating']=[]\n",
    "prod_dict['No. of ratings']=[]\n",
    "prod_dict['Price']=[]\n",
    "prod_dict['Return/Exchange']=[]\n",
    "prod_dict['Expected Delivery']=[] \n",
    "prod_dict['Availability']=[]\n",
    "prod_dict['Other Details']=[]\n",
    "prod_dict['URL']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78060ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:4]:\n",
    "    driver.get(url)\n",
    "    print('scraping url', url)\n",
    "    \n",
    "    try:\n",
    "        Brand=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Brand'].append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Brand'].append('_')\n",
    "    \n",
    "    try:\n",
    "        Name=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Name'].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Name'].append('_')\n",
    "    \n",
    "    try:\n",
    "        Rating=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Rating'].append(Rating.get_attribute('title'))\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Rating'].append('_')\n",
    "    \n",
    "    try:\n",
    "        N_ratings=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['No. of ratings'].append(N_ratings.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['No. of ratings'].append('_')\n",
    "    \n",
    "    try:\n",
    "        Price=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Price'].append(Price.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Price'].append('_')\n",
    "    \n",
    "    try:\n",
    "        rnt=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Return/Exchange'].append(rnt.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Return/Exchange'].append('_')\n",
    "    \n",
    "    try:\n",
    "        Delivery=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Expected Delivery'].append(Delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Expected Delivery'].append('_')\n",
    "    \n",
    "    try:\n",
    "        Availability=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Availability'].append(Availability.text)\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Availability'].append('_')\n",
    "    \n",
    "    try:\n",
    "        dtls=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-base\"]')\n",
    "        prod_dict['Other Details'].append('        '.join(dtls.text.split('\\n')))\n",
    "    except NoSuchElementException:\n",
    "        prod_dict['Other Details'].append('_')\n",
    "    \n",
    "        prod_dict['URL'].append(url)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "863d901c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'prod_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Product_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod_dict\u001b[49m(prod_dict)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'prod_dict'"
     ]
    }
   ],
   "source": [
    "# Saving data to data Frame\n",
    "Product_df = pd.DataFrame.prod_dict(prod_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9eb421",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Product_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Saving data to csv file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mProduct_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(user_inp))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Product_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving data to csv file\n",
    "Product_df.to_csv('Product_{}.csv'.format(user_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f1383",
   "metadata": {},
   "source": [
    "Q3. Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0389a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for webdriver\n",
    "driver = webdriver.Chrome(r\"E:\\Flip Robo\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c312265",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://images.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b3a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"gLFyf gsfi\"]')\n",
    "search.send_keys('fruits')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a2a1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a3706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "\n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a0bea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print('Downloading {0} of {1} images'.format(i, 10))\n",
    "    responce = requests.get(img_urls[i])\n",
    "    file = open(\"E:/Flip Robo/image/img\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "555e7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"gLFyf gsfi\"]')\n",
    "search.send_keys('cars')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9463120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1231182d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "        \n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3965ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 image\n",
      "Downloading 1 of 10 image\n",
      "Downloading 2 of 10 image\n",
      "Downloading 3 of 10 image\n",
      "Downloading 4 of 10 image\n",
      "Downloading 5 of 10 image\n",
      "Downloading 6 of 10 image\n",
      "Downloading 7 of 10 image\n",
      "Downloading 8 of 10 image\n",
      "Downloading 9 of 10 image\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print('Downloading {0} of {1} image' .format(i, 10))\n",
    "    responce = requests.get(img_urls[i])\n",
    "    file = open('E:\\Flip Robo\\image\\img'+str(i)+ \".jpg\", \"wb\")\n",
    "    file.write(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23ec274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c375f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"gLFyf gsfi\"]')\n",
    "search.send_keys('Machine Learning')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed9f0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09e0ffce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "        \n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af7f9f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 image\n",
      "Downloading 1 of 10 image\n",
      "Downloading 2 of 10 image\n",
      "Downloading 3 of 10 image\n",
      "Downloading 4 of 10 image\n",
      "Downloading 5 of 10 image\n",
      "Downloading 6 of 10 image\n",
      "Downloading 7 of 10 image\n",
      "Downloading 8 of 10 image\n",
      "Downloading 9 of 10 image\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print('Downloading {0} of {1} image' .format(i, 10))\n",
    "    responce = requests.get(img_urls[i])\n",
    "    file = open('E:\\Flip Robo\\image\\img'+str(i)+ \".jpg\", \"wb\")\n",
    "    file.write(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e632b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5972c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"gLFyf gsfi\"]')\n",
    "search.send_keys('Guitar')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a13d5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3fe9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "        \n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d597305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 image\n",
      "Downloading 1 of 10 image\n",
      "Downloading 2 of 10 image\n",
      "Downloading 3 of 10 image\n",
      "Downloading 4 of 10 image\n",
      "Downloading 5 of 10 image\n",
      "Downloading 6 of 10 image\n",
      "Downloading 7 of 10 image\n",
      "Downloading 8 of 10 image\n",
      "Downloading 9 of 10 image\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print('Downloading {0} of {1} image' .format(i, 10))\n",
    "    responce = requests.get(img_urls[i])\n",
    "    file = open('E:\\Flip Robo\\image\\img'+str(i)+ \".jpg\", \"wb\")\n",
    "    file.write(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf85abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://image.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28875ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"gLFyf gsfi\"]')\n",
    "search.send_keys('Cakes')\n",
    "\n",
    "search_button = driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc99fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8601ddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source = image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49aeab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading0 of 10 image\n",
      "Downloading1 of 10 image\n",
      "Downloading2 of 10 image\n",
      "Downloading3 of 10 image\n",
      "Downloading4 of 10 image\n",
      "Downloading5 of 10 image\n",
      "Downloading6 of 10 image\n",
      "Downloading7 of 10 image\n",
      "Downloading8 of 10 image\n",
      "Downloading9 of 10 image\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_urls)):\n",
    "    if i >=10:\n",
    "        break\n",
    "    print('Downloading{0} of {1} image' .format(i, 10))\n",
    "    responce = requests.get(img_urls[i])\n",
    "    file = open(\"E:\\Flip Robo\\image\\img\"+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469168a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be64cb",
   "metadata": {},
   "source": [
    "Q4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be\n",
    "scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697cf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'E:\\Flip Robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1168be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3a08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Button to close login popup\n",
    "try:\n",
    "    login_close_button = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')                      \n",
    "    login_close_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No Login page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3e46b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the products using searchbar by it's xpath\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys('Oneplus Nord') # input key word to search\n",
    "\n",
    "search_btn = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click() # clicking the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54214b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "urls = driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')\n",
    "for url in urls:\n",
    "    url.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3b9bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb68661",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dict = {}\n",
    "p_dict[\"Brand\"] = []\n",
    "p_dict[\"Smartphone\"] = []\n",
    "p_dict[\"Colour\"] = []\n",
    "p_dict[\"RAM\"] = []\n",
    "p_dict[\"Storage(ROM)\"] = []\n",
    "p_dict[\"Primary Camera\"] = []\n",
    "p_dict[\"Secondary Camera\"] = []\n",
    "p_dict[\"Display Size\"] = []\n",
    "p_dict[\"Display Resolution\"] = []\n",
    "p_dict[\"Processor\"] = []\n",
    "p_dict[\"Processor Cores\"] = []\n",
    "p_dict[\"Battery Capacity\"] = []\n",
    "p_dict[\"Battery Type\"] = []\n",
    "p_dict[\"Price\"] = []\n",
    "p_dict[\"URL\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e5bcac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'url' must be a string\n  (Session info: chrome=105.0.5195.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006978B3+2193587]\n\tOrdinal0 [0x00630681+1771137]\n\tOrdinal0 [0x005441A8+803240]\n\tOrdinal0 [0x0059E256+1172054]\n\tOrdinal0 [0x0058D7AC+1103788]\n\tOrdinal0 [0x0059DAE2+1170146]\n\tOrdinal0 [0x0058D5C6+1103302]\n\tOrdinal0 [0x005677E0+948192]\n\tOrdinal0 [0x005686E6+952038]\n\tGetHandleVerifier [0x00940CB2+2738370]\n\tGetHandleVerifier [0x009321B8+2678216]\n\tGetHandleVerifier [0x007217AA+512954]\n\tGetHandleVerifier [0x00720856+509030]\n\tOrdinal0 [0x0063743B+1799227]\n\tOrdinal0 [0x0063BB68+1817448]\n\tOrdinal0 [0x0063BC55+1817685]\n\tOrdinal0 [0x00645230+1856048]\n\tBaseThreadInitThunk [0x7633FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Scraping data from each url\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m                                                         \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping URL = \u001b[39m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[0;32m      5\u001b[0m     p_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(url)                                                          \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'url' must be a string\n  (Session info: chrome=105.0.5195.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006978B3+2193587]\n\tOrdinal0 [0x00630681+1771137]\n\tOrdinal0 [0x005441A8+803240]\n\tOrdinal0 [0x0059E256+1172054]\n\tOrdinal0 [0x0058D7AC+1103788]\n\tOrdinal0 [0x0059DAE2+1170146]\n\tOrdinal0 [0x0058D5C6+1103302]\n\tOrdinal0 [0x005677E0+948192]\n\tOrdinal0 [0x005686E6+952038]\n\tGetHandleVerifier [0x00940CB2+2738370]\n\tGetHandleVerifier [0x009321B8+2678216]\n\tGetHandleVerifier [0x007217AA+512954]\n\tGetHandleVerifier [0x00720856+509030]\n\tOrdinal0 [0x0063743B+1799227]\n\tOrdinal0 [0x0063BB68+1817448]\n\tOrdinal0 [0x0063BC55+1817685]\n\tOrdinal0 [0x00645230+1856048]\n\tBaseThreadInitThunk [0x7633FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B2E+238]\n"
     ]
    }
   ],
   "source": [
    "# Scraping data from each url\n",
    "for url in urls:\n",
    "    driver.get(url)                                                         \n",
    "    print(\"Scraping URL = \", url)\n",
    "    p_dict['URL'].append(url)                                                          \n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        read_more = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _1FH0tX\"]')     \n",
    "        read_more.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception Occured. Moving to next page\")\n",
    "    \n",
    "    try:\n",
    "        brand = driver.find_element_by_xpath('//span[@class=\"B_NuCI\"]')      \n",
    "        p_dict[\"Brand\"].append(brand.text.split()[0])\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Brand'].append('-')\n",
    "        \n",
    "    try:\n",
    "        price = driver.find_element_by_xpath('//div[@class=\"_30jeq3 _16Jk6d\"]')      \n",
    "        p_dict['Price'].append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Price'].append('-')\n",
    "        \n",
    "    try:\n",
    "        name = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')      \n",
    "        p_dict['Smartphone'].append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Smartphone'].append('-')\n",
    "    \n",
    "    try:\n",
    "        color = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')      \n",
    "        p_dict['Colour'].append(color.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Colour'].append('-')\n",
    "    \n",
    "    try:\n",
    "        disp_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/div')\n",
    "        if disp_chk.text != \"Display Features\" : raise NoSuchElementException\n",
    "        p_dict = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table[1]/tbody/tr[1]/td[2]/ul/li')  \n",
    "        p_dict['Display Size'].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Display Size'].append('-')\n",
    "    \n",
    "    try:\n",
    "        disp_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/div')\n",
    "        if disp_chk.text != \"Display Features\" : raise NoSuchElementException\n",
    "        disp_res = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][2]/table[1]/tbody/tr[2]/td[2]/ul/li')     \n",
    "        p_dict['Display Resolution'].append(disp_res.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Display Resolution'].append('-')\n",
    "    \n",
    "    try:\n",
    "        pro_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[1]')\n",
    "        if pro_chk.text != \"Processor Type\" : raise NoSuchElementException\n",
    "        processor = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[2]/ul/li')   \n",
    "        p_dict['Processor'].append(processor.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Processor'].append('-')\n",
    "    \n",
    "    try:                                                                                     \n",
    "        core_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[3]/td[1]')\n",
    "        if core_chk.text != \"Processor Core\" :\n",
    "            core_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[1]')\n",
    "            if core_chk.text != \"Processor Core\" : \n",
    "                raise NoSuchElementException\n",
    "            else :\n",
    "                cores = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[2]/td[2]/ul/li')\n",
    "        else :\n",
    "            cores = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][3]/table[1]/tbody/tr[3]/td[2]/ul/li')\n",
    "        p_dict['Processor Cores'].append(cores.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Processor Cores'].append('-')\n",
    "    \n",
    "    try:\n",
    "        rom = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[1]/td[2]/ul/li')         \n",
    "        p_dict['Storage(ROM)'].append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Storage(ROM)'].append('-')\n",
    "    \n",
    "    try:\n",
    "        ram = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[2]/td[2]/ul/li')                \n",
    "        p_dict['RAM'].append(ram.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['RAM'].append('-')\n",
    "    \n",
    "    try:                                                                                    \n",
    "        pri_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[2]/td[2]/ul/li')\n",
    "        p_dict['Primary Camera'].append(pri_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Primary Camera'].append('-')\n",
    "    \n",
    "    try:                                                                                    \n",
    "        cam_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[6]/td[1]')\n",
    "        if cam_chk != \"Secondary Camera\" : \n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[5]/td[1]').text == \"Secondary Camera\":\n",
    "                sec_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[5]/td[2]/ul/li')\n",
    "            else :\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            sec_cam = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[6]/td[2]/ul/li')\n",
    "        p_dict['Secondary Camera'].append(sec_cam.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Secondary Camera'].append('-')\n",
    "        \n",
    "    try:\n",
    "        if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/div').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[1]')\n",
    "                if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[2]/ul/li')                \n",
    "            elif driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[1]')\n",
    "                if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[1]')\n",
    "            if bat_chk.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_cap = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[2]/ul/li')                \n",
    "        p_dict['Battery Capacity'].append(bat_cap.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Battery Capacity'].append('-')\n",
    "    \n",
    "    try:\n",
    "        if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/div').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr[2]/td[1]')\n",
    "                if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "                bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            elif driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/div').text == \"Battery & Power Features\" :\n",
    "                bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr[2]/td[1]')\n",
    "                if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "                bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_chk = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr[2]/td[1]')\n",
    "            if bat_chk.text != \"Battery Type\" : raise NoSuchElementException\n",
    "            bat_typ = driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr[2]/td[2]/ul/li')                \n",
    "        p_dict['Battery Type'].append(bat_typ.text)\n",
    "    except NoSuchElementException:\n",
    "        p_dict['Battery Type'].append('-')\n",
    "    \n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0f4553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(p_dict[\"Brand\"]), len(p_dict[\"Smartphone\"]), len(p_dict[\"Processor\"]), len(p_dict[\"Price\"]), len(p_dict['URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "779dae2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Colour</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Storage(ROM)</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Secondary Camera</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Display Resolution</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Processor Cores</th>\n",
       "      <th>Battery Capacity</th>\n",
       "      <th>Battery Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Smartphone, Colour, RAM, Storage(ROM), Primary Camera, Secondary Camera, Display Size, Display Resolution, Processor, Processor Cores, Battery Capacity, Battery Type, Price, URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict = pd.DataFrame.from_dict(p_dict)\n",
    "p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "255e4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271c8f4",
   "metadata": {},
   "source": [
    "Q5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google\n",
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a2e6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'E:\\Flip Robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2949436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening google maps\n",
    "driver.get(\"https://www.google.co.in/maps\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "494a4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@class=\"tactile-searchbox-input\"]')                      \n",
    "search.send_keys('delhi')                                                    \n",
    "button = driver.find_element(By.XPATH,'//*[@class=\"pzfvzf\"]')         \n",
    "button.click()                                                            \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f10ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c12d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted:  https://www.google.co.in/maps/place/Delhi/@28.6458177,76.5341356,9z/data=!4m5!3m4!1s0x390cfd5b347eb62d:0x37205b715389640!8m2!3d28.7040592!4d77.1024902\n",
      "Latitude = 28.6458177, Longitude = 76.5341356\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37bd136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea3ea50",
   "metadata": {},
   "source": [
    "Q6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21)\n",
    "from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b639b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'E:\\Flip Robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5496ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.trak.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7360ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH,'//li[@id=\"menu-item-51510\"]/a')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13cd1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dict = {}\n",
    "f_dict['Date'] = []\n",
    "f_dict['Startup_Name'] = []\n",
    "f_dict['Industry/Vertical'] = []\n",
    "f_dict['Sub-Vertical'] = []\n",
    "f_dict['Location'] = []\n",
    "f_dict['Investor'] = []\n",
    "f_dict['Investment_Type'] = []\n",
    "f_dict['Amount(in USD)'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc9a6e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2871787082.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [107]\u001b[1;36m\u001b[0m\n\u001b[1;33m    f_dict['Date'].append(date.text)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for i in range(48,51):\n",
    "    driver.find_element(By.XPATH,'//div[@id=\"tablepress-{}_wrapper\"]/div/label/select/option[4]'.format(i)).click()\n",
    "\n",
    "    # Date\n",
    "    date = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[2]'.format(i))\n",
    "        f_dict['Date'].append(date.text)\n",
    "\n",
    "    # Startup Name\n",
    "    Startup_Name = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[3]'.format(i))\n",
    "        f_dict['Startup_Name'].append(Startup_Name.text)\n",
    "    \n",
    "    # Industry/Vertical\n",
    "    Industry/Vertical = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[4]'.format(i))\n",
    "        f_dict['Industry/Vertical'].append(Industry/Vertical.text)\n",
    "    \n",
    "    # Sub-Vertical\n",
    "    Sub-Vertical = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[5]'.format(i))\n",
    "        f_dict['Sub-Vertical'].append(Sub-Vertical.text)\n",
    "\n",
    "    # Location\n",
    "    Location = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[6]'.format(i))\n",
    "        f_dict['Location'].append(Location.text)\n",
    "    \n",
    "    # Investor\n",
    "    Investor = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[7]'.format(i))\n",
    "        f_dict['Investor'].append(Investor.text)\n",
    "    \n",
    "    # Investment Type\n",
    "    Investment_Type = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[8]'.format(i))\n",
    "        f_dict['Investment_Type'].append(Investment_Type.text)\n",
    "    \n",
    "    # Amount\n",
    "    Amount = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[9]'.format(i))\n",
    "    for amt in Amount:\n",
    "        f_dict['Amount(in USD)'].append(amt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e5956bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>Location</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount(in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Singapore and Bangalore</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>New York and Delhi</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Stanford, California,</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03/08/2020</td>\n",
       "      <td>CrowdPouch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Elina Investments Pvt. Ltd</td>\n",
       "      <td>Angel</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>DrinkPrime</td>\n",
       "      <td>Water Purification</td>\n",
       "      <td>Water Purification</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Sequoia Surge, ON Mauritius</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>2,880,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Cell Propulsion</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Electric Mobility Solutions</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>growX Ventures and Micelio</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date               Startup Name  \\\n",
       "0   15/07/2020                   Flipkart   \n",
       "1   16/07/2020                    Vedantu   \n",
       "2   16/07/2020                       Crio   \n",
       "3   14/07/2020                    goDutch   \n",
       "4   13/07/2020                   Mystifly   \n",
       "5   09/07/2020               JetSynthesys   \n",
       "6   10/07/2020                   gigIndia   \n",
       "7   15/07/2020                  PumPumPum   \n",
       "8   14/07/2020                       FLYX   \n",
       "9   13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "10  15/08/2020                     Practo   \n",
       "11  13/08/2020                    Medlife   \n",
       "12  13/08/2020                  HungerBox   \n",
       "13  04/08/2020                      Dunzo   \n",
       "14  11/08/2020                   Terra.do   \n",
       "15  12/08/2020                  Classplus   \n",
       "16  14/08/2020                       Niyo   \n",
       "17  10/08/2020                  ZestMoney   \n",
       "18  07/08/2020                FreshToHome   \n",
       "19  13/08/2020                    Eduvanz   \n",
       "20  03/08/2020                 CrowdPouch   \n",
       "21  04/08/2020                 DrinkPrime   \n",
       "22  08/09/2020                     Byju’s   \n",
       "23  12/09/2020                  mCaffeine   \n",
       "24  09/09/2020                     Qshala   \n",
       "25  02/09/2020                      Winzo   \n",
       "26  09/09/2020                Hippo Video   \n",
       "27  07/09/2020                    Melorra   \n",
       "28  07/09/2020                        1mg   \n",
       "29  31/08/2020                      mfine   \n",
       "30  31/08/2020                       Apna   \n",
       "31  03/09/2020                    Railofy   \n",
       "32  08/09/2020            Cell Propulsion   \n",
       "\n",
       "                         Industry/Vertical  \\\n",
       "0                               E-commerce   \n",
       "1                                  EduTech   \n",
       "2                                  EduTech   \n",
       "3                                  FinTech   \n",
       "4                      Airfare Marketplace   \n",
       "5                 Gaming and Entertainment   \n",
       "6                              Marketplace   \n",
       "7                        Automotive Rental   \n",
       "8                               OTT Player   \n",
       "9                   Information Technology   \n",
       "10                              HealthTech   \n",
       "11                              E-commerce   \n",
       "12                                FoodTech   \n",
       "13                   Hyper-local Logistics   \n",
       "14                                 EduTech   \n",
       "15                                 EduTech   \n",
       "16                                 FinTech   \n",
       "17                                 FinTech   \n",
       "18                              E-commerce   \n",
       "19                                 FinTech   \n",
       "20                                 FinTech   \n",
       "21                      Water Purification   \n",
       "22                                 EduTech   \n",
       "23                           Personal Care   \n",
       "24                                 EduTech   \n",
       "25                           Online Gaming   \n",
       "26  Video Customer Experience(CX) Platform   \n",
       "27                              E-commerce   \n",
       "28                              E-commerce   \n",
       "29                              HealthTech   \n",
       "30                         Human Resources   \n",
       "31                          Transportation   \n",
       "32                              Automobile   \n",
       "\n",
       "                                         Sub-Vertical  \\\n",
       "0                                          E-commerce   \n",
       "1                                     Online Tutoring   \n",
       "2                    Learning Platform for Developers   \n",
       "3                                      Group Payments   \n",
       "4   Ticketing, Airline Retailing, and Post-Ticketi...   \n",
       "5                            Gaming and Entertainment   \n",
       "6                           Crowd Sourcing, Freelance   \n",
       "7                           Used Car-leasing platform   \n",
       "8                            Streaming Social Network   \n",
       "9               Internet-of-Things Security Solutions   \n",
       "10                           Health care and Wellness   \n",
       "11                                    Online Pharmacy   \n",
       "12                       Online Food Delivery Service   \n",
       "13                           Online Delivery Services   \n",
       "14                  Online Climate School, E-learning   \n",
       "15                        E-learning, Online Tutoring   \n",
       "16                                 Financial Services   \n",
       "17                                 Financial Services   \n",
       "18                                      Food Delivery   \n",
       "19                                 Financial Services   \n",
       "20                                 Financial Services   \n",
       "21                                 Water Purification   \n",
       "22                                    Online Tutoring   \n",
       "23                                Skincare & Haircare   \n",
       "24                 Online Curiosity Platform for Kids   \n",
       "25                                      Online Gaming   \n",
       "26             Video Customer Experience(CX) Platform   \n",
       "27                               Online Jewelry Store   \n",
       "28                                    Online Pharmacy   \n",
       "29                      On-Demand Healthcare Services   \n",
       "30                               Recruitment Platform   \n",
       "31                       WL & RAC protection platform   \n",
       "32                        Electric Mobility Solutions   \n",
       "\n",
       "                                      Location  \\\n",
       "0                                    Bangalore   \n",
       "1                                    Bangalore   \n",
       "2                                    Bangalore   \n",
       "3                                       Mumbai   \n",
       "4                      Singapore and Bangalore   \n",
       "5                                         Pune   \n",
       "6                                         Pune   \n",
       "7                                      Gurgaon   \n",
       "8                           New York and Delhi   \n",
       "9                                    Bangalore   \n",
       "10                                   Bangalore   \n",
       "11                                   Bangalore   \n",
       "12                                   Bangalore   \n",
       "13                                   Bangalore   \n",
       "14                       Stanford, California,   \n",
       "15                                       Noida   \n",
       "16                                   Bangalore   \n",
       "17                                   Bangalore   \n",
       "18                                   Bangalore   \n",
       "19                                      Mumbai   \n",
       "20                                   Bangalore   \n",
       "21                                   Bangalore   \n",
       "22                                   Bangalore   \n",
       "23                                      Mumbai   \n",
       "24                                   Bangalore   \n",
       "25                                   New Delhi   \n",
       "26  Newark, Delaware, United States of Amercia   \n",
       "27                                   Bangalore   \n",
       "28                                     Gurgaon   \n",
       "29                                   Bangalore   \n",
       "30                                   Bangalore   \n",
       "31                                      Mumbai   \n",
       "32                                   Bangalore   \n",
       "\n",
       "                                             Investor         Investment Type  \\\n",
       "0                                         Walmart Inc                     M&A   \n",
       "1                                   Coatue Management                Series D   \n",
       "2                                         021 Capital            pre-Series A   \n",
       "3   Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "4                                    Recruit Co. Ltd.            pre-Series B   \n",
       "5            Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "6        Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "7                            Early Adapters Syndicate                    Seed   \n",
       "8               Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "9                              Unicorn India Ventures  Venture-Series Unknown   \n",
       "10                                        A1A Company                Series F   \n",
       "11         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "12  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "13                                   Existing Backers             In Progress   \n",
       "14  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "15                                        Falcon Edge             In Progress   \n",
       "16                                Niyo Solutions Inc.                           \n",
       "17                            Primrose Hills Ventures                           \n",
       "18                                     Ascent Capital                 Venture   \n",
       "19                              Sequoia India, Unitus                Series A   \n",
       "20                         Elina Investments Pvt. Ltd                   Angel   \n",
       "21                        Sequoia Surge, ON Mauritius            Pre-Series A   \n",
       "22  Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "23  Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "24                                 Rainmatter Capital                   Angel   \n",
       "25  Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "26  Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "27                         Shadow Holdings, Lightbox.          Debt Financing   \n",
       "28         Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "29                                   Caretech Pte Inc                Series B   \n",
       "30         Lightspeed India and Sequoia Capital India                Series A   \n",
       "31                                  Chiratae Ventures                    Seed   \n",
       "32                         growX Ventures and Micelio            pre-Series A   \n",
       "\n",
       "     Amount(in USD)  \n",
       "0     1,200,000,000  \n",
       "1       100,000,000  \n",
       "2           934,160  \n",
       "3         1,700,000  \n",
       "4         3,300,000  \n",
       "5           400,000  \n",
       "6           974,200  \n",
       "7           292,800  \n",
       "8           200,000  \n",
       "9           500,000  \n",
       "10       32,000,000  \n",
       "11       23,000,000  \n",
       "12        1,560,000  \n",
       "13       30,000,000  \n",
       "14        1,400,000  \n",
       "15  upto 15,000,000  \n",
       "16        6,000,000  \n",
       "17       10,670,000  \n",
       "18       16,200,000  \n",
       "19        5,000,000  \n",
       "20               NA  \n",
       "21        2,880,000  \n",
       "22      500,000,000  \n",
       "23        3,000,000  \n",
       "24          370,000  \n",
       "25       15,500,000  \n",
       "26        4,500,000  \n",
       "27   upto 8,900,000  \n",
       "28      100,000,000  \n",
       "29        5,400,000  \n",
       "30        8,000,000  \n",
       "31          950,000  \n",
       "32               NA  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund_df = pd.DataFrame(f_dict)\n",
    "fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45f943bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_df.to_csv(\"Indian Startups_Q1_2021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90badcbf",
   "metadata": {},
   "source": [
    "Q7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3790cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'E:\\Flip Robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f3a7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.digit.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "04b0c4cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//ul[@id='top10list']/li[2]\"}\n  (Session info: chrome=105.0.5195.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006978B3+2193587]\n\tOrdinal0 [0x00630681+1771137]\n\tOrdinal0 [0x005441A8+803240]\n\tOrdinal0 [0x005724A0+992416]\n\tOrdinal0 [0x0057273B+993083]\n\tOrdinal0 [0x0059F7C2+1177538]\n\tOrdinal0 [0x0058D7F4+1103860]\n\tOrdinal0 [0x0059DAE2+1170146]\n\tOrdinal0 [0x0058D5C6+1103302]\n\tOrdinal0 [0x005677E0+948192]\n\tOrdinal0 [0x005686E6+952038]\n\tGetHandleVerifier [0x00940CB2+2738370]\n\tGetHandleVerifier [0x009321B8+2678216]\n\tGetHandleVerifier [0x007217AA+512954]\n\tGetHandleVerifier [0x00720856+509030]\n\tOrdinal0 [0x0063743B+1799227]\n\tOrdinal0 [0x0063BB68+1817448]\n\tOrdinal0 [0x0063BC55+1817685]\n\tOrdinal0 [0x00645230+1856048]\n\tBaseThreadInitThunk [0x7633FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [139]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m top_10\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#clicking on laptops option\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m laptops\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//ul[@id=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop10list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]/li[2]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m laptops\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#best gaming laptops link\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:855\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    852\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    853\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//ul[@id='top10list']/li[2]\"}\n  (Session info: chrome=105.0.5195.127)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x006978B3+2193587]\n\tOrdinal0 [0x00630681+1771137]\n\tOrdinal0 [0x005441A8+803240]\n\tOrdinal0 [0x005724A0+992416]\n\tOrdinal0 [0x0057273B+993083]\n\tOrdinal0 [0x0059F7C2+1177538]\n\tOrdinal0 [0x0058D7F4+1103860]\n\tOrdinal0 [0x0059DAE2+1170146]\n\tOrdinal0 [0x0058D5C6+1103302]\n\tOrdinal0 [0x005677E0+948192]\n\tOrdinal0 [0x005686E6+952038]\n\tGetHandleVerifier [0x00940CB2+2738370]\n\tGetHandleVerifier [0x009321B8+2678216]\n\tGetHandleVerifier [0x007217AA+512954]\n\tGetHandleVerifier [0x00720856+509030]\n\tOrdinal0 [0x0063743B+1799227]\n\tOrdinal0 [0x0063BB68+1817448]\n\tOrdinal0 [0x0063BC55+1817685]\n\tOrdinal0 [0x00645230+1856048]\n\tBaseThreadInitThunk [0x7633FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77D47B2E+238]\n"
     ]
    }
   ],
   "source": [
    "#clickng on top 10 option \n",
    "top_10=driver.find_element(By.XPATH,\"//div[@class='menu']/ul/li[3]/a\")\n",
    "top_10.click()\n",
    "\n",
    "#clicking on laptops option\n",
    "laptops=driver.find_element(By.XPATH,\"//ul[@id='top10list']/li[2]\")\n",
    "laptops.click()\n",
    "\n",
    "#best gaming laptops link\n",
    "best_gaming=driver.find_element(By.XPATH,\"//div[@id='laptops']/a[3]\")\n",
    "driver.get(best_gaming.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d68c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists\n",
    "name = []\n",
    "price = []\n",
    "OS = []\n",
    "display = []\n",
    "processor = []\n",
    "HDD = []\n",
    "RAM = []\n",
    "weight = []\n",
    "dimension = []\n",
    "GPU = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#names\n",
    "names=driver.find_element(By.XPATH,\"//div[@class='right-container']/div/a/h3\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "#os\n",
    "os=driver.find_element(By.XPATH,\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "for i in os:\n",
    "    OS.append(i.text)\n",
    "    \n",
    "#display\n",
    "displays=driver.find_element(By.XPATH,\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "for i in displays:\n",
    "    display.append(i.text)\n",
    "    \n",
    "#processor\n",
    "processors=driver.find_element(By.XPATH,\"//div[@class='product-detail']/div/ul/li[3]/div/div\")\n",
    "for i in processors:\n",
    "    processor.append(i.text)\n",
    "processor\n",
    "\n",
    "#memory\n",
    "memories=driver.find_element(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[1]\")#list of specificaion name\n",
    "memories_spec=driver.find_element(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")#values of specifiations \n",
    "for i in range(len(memories)):\n",
    "        if memories[i].text=='Memory':\n",
    "            HDD.append(memories_spec[i].text.split('/')[0])\n",
    "            RAM.append(memories_spec[i].text.split('/')[1])\n",
    "        else:\n",
    "            HDD.append('No details available')#append no details as value for memory is missing in some of the laptops\n",
    "            RAM.append('No details available')#append no details as value for memory is missing in some of the laptops\n",
    "\n",
    "#weight\n",
    "weights=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "weight_spec=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(weights)):\n",
    "        if weights[i].text=='Weight':\n",
    "            weight.append(weight_spec[i].text)\n",
    "        \n",
    "#dimension\n",
    "dimension=[]\n",
    "dims=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "dims_spec=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(dims)):\n",
    "        if dims[i].text=='Dimension':\n",
    "            dimension.append(dims_spec[i].text)\n",
    "\n",
    "#graphical processor\n",
    "GPUs=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[1]\")#list of specificaion name\n",
    "GPUs_spec=driver.find_element(By.XPATH,\"//div[@class='Spcs-details']/table/tbody/tr/td[3]\")#values of specifiations\n",
    "for i in range(len(GPUs)):\n",
    "        if GPUs[i].text=='Graphics Processor':\n",
    "            GPU.append(GPUs_spec[i].text)\n",
    "        \n",
    "full_specs=[]\n",
    "urls=driver.find_element(By.XPATH,\"//div[@class='full-specs']/span\")#getting the url of full specs links\n",
    "for i in urls:\n",
    "    if i.get_attribute('data-href'):\n",
    "        full_specs.append(i.get_attribute('data-href'))\n",
    "    \n",
    "for i in full_specs:#iterating throug every laptops full specs' page\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prices=driver.find_element(By.XPATH,\"//div[@class='Block-price']/b\")\n",
    "        price.append(prices.text)\n",
    "    except NoSuchElementException:#exception handling for no price details\n",
    "        price.append(\"No details available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "781a7dec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43mname\u001b[49m,\n\u001b[0;32m      2\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m:price,\n\u001b[0;32m      3\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS\u001b[39m\u001b[38;5;124m\"\u001b[39m:OS,\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m:display,\n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHDD\u001b[39m\u001b[38;5;124m\"\u001b[39m:HDD,\n\u001b[0;32m      6\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAM\u001b[39m\u001b[38;5;124m\"\u001b[39m:RAM,\n\u001b[0;32m      7\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m:processor,\n\u001b[0;32m      8\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m:weight,\n\u001b[0;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension\u001b[39m\u001b[38;5;124m\"\u001b[39m:dimension,\n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphical processor\u001b[39m\u001b[38;5;124m\"\u001b[39m:GPU})\n\u001b[0;32m     11\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":name,\n",
    "                \"Price\":price,\n",
    "                \"OS\":OS,\n",
    "                \"Display\":display,\n",
    "                \"HDD\":HDD,\n",
    "                 \"RAM\":RAM,\n",
    "                \"processor\":processor,\n",
    "                \"weight\":weight,\n",
    "                \"Dimension\":dimension,\n",
    "                \"Graphical processor\":GPU})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e36b716c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaming laptops_digit.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"Gaming laptops_digit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffcbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fd689",
   "metadata": {},
   "source": [
    "Q8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be\n",
    "scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "66a55194",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.forbes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d3ebd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH,'/html/body/div[1]/main/section[8]/div[1]')\n",
    "button.click()\n",
    "\n",
    "title = driver.find_element(By.XPATH,'//a[@class=\"stream-item__title\"]')\n",
    "title.click()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1f0a6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for Scraping \n",
    "Rank = []\n",
    "Name = []\n",
    "Net_Worth = []\n",
    "Age = []\n",
    "Citizenship = []\n",
    "Source = []\n",
    "Industry = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb44c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98aae36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fa868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8e353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321e94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fde4520a",
   "metadata": {},
   "source": [
    "Q9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7478a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceebfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c104467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d68ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035e960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5335f1e",
   "metadata": {},
   "source": [
    "Q10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews,\n",
    "overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8a700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c93388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481fc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c6ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0defec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3ad85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
